{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ted Talk Topic Extraction with [NMF](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into pandas dataframes\n",
    "transcript_df = pd.read_csv('data/transcripts.csv')\n",
    "main_df = pd.read_csv('data/ted_main.csv', parse_dates=['film_date', 'published_date'],\n",
    "                      converters={'ratings': literal_eval, 'tags': literal_eval, 'related_talks': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model parameters\n",
    "MIN_DF = 0.1\n",
    "MAX_DF = 0.2\n",
    "NUM_TOPICS = 10\n",
    "MORE_STOPWORDS = set(['talk', 'applause', 'laughter', 'yeah', 'oh', 'guy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile stopwords and create TFIDF vectorizer for transcript data\n",
    "en_stop = en_stop | MORE_STOPWORDS\n",
    "vectorizer = TfidfVectorizer(stop_words=en_stop,\n",
    "                             use_idf=True,\n",
    "                             ngram_range=(1, 1),\n",
    "                             min_df=MIN_DF,\n",
    "                             max_df=MAX_DF)\n",
    "\n",
    "tfidf = vectorizer.fit_transform(transcript_df['transcript'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit NMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['father', 'god', 'war', 'girl', 'parents']\n",
      "1 ['music', 'sound', 'playing', 'sounds', 'audience']\n",
      "2 ['species', 'animals', 'planet', 'sea', 'animal']\n",
      "3 ['cancer', 'disease', 'medical', 'blood', 'hospital']\n",
      "4 ['africa', 'economic', 'companies', 'economy', 'china']\n",
      "5 ['computer', 'machine', 'internet', 'digital', 'computers']\n",
      "6 ['cities', 'car', 'cars', 'street', 'driving']\n",
      "7 ['universe', 'theory', 'sun', 'planet', 'black']\n",
      "8 ['students', 'education', 'learning', 'language', 'schools']\n",
      "9 ['cells', 'cell', 'blood', 'disease', 'lab']\n"
     ]
    }
   ],
   "source": [
    "# create, fit nmf model and transform tfidf vectorizer\n",
    "nmf = NMF(n_components=NUM_TOPICS, random_state=42)\n",
    "topics = nmf.fit_transform(tfidf)\n",
    "\n",
    "# print top 5 words associated with each fitted topic\n",
    "top_n_words = 5\n",
    "t_words, word_strengths = {}, {}\n",
    "for t_id, t in enumerate(nmf.components_):\n",
    "    t_words[t_id] = [vectorizer.get_feature_names()[i] for i in t.argsort()[:-top_n_words - 1:-1]]\n",
    "    word_strengths[t_id] = t[t.argsort()[:-top_n_words - 1:-1]]\n",
    "for k, v in t_words.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing out NMF fit on 5 randomly sampled talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted most likely topic:  ['father', 'god', 'war', 'girl', 'parents']\n",
      "Talk Title: ['How to speak so that people want to listen']\n",
      "Actual Talk Tags: [list(['culture', 'sound', 'speech'])]\n",
      "----------------------------------------------------\n",
      "Predicted most likely topic:  ['computer', 'machine', 'internet', 'digital', 'computers']\n",
      "Talk Title: ['How to make a splash in social media']\n",
      "Actual Talk Tags: [list(['Internet', 'animals', 'business', 'culture', 'entertainment', 'entrepreneur', 'oceans', 'web'])]\n",
      "----------------------------------------------------\n",
      "Predicted most likely topic:  ['cities', 'car', 'cars', 'street', 'driving']\n",
      "Talk Title: ['The ghastly tragedy of the suburbs']\n",
      "Actual Talk Tags: [list(['alternative energy', 'architecture', 'cars', 'cities', 'consumerism', 'culture', 'design', 'energy', 'transportation'])]\n",
      "----------------------------------------------------\n",
      "Predicted most likely topic:  ['father', 'god', 'war', 'girl', 'parents']\n",
      "Talk Title: ['Drawing on humor for change']\n",
      "Actual Talk Tags: [list(['art', 'comedy', 'culture', 'feminism', 'humor', 'media', 'peace', 'women'])]\n",
      "----------------------------------------------------\n",
      "Predicted most likely topic:  ['father', 'god', 'war', 'girl', 'parents']\n",
      "Talk Title: ['\"Kiteflyer\\'s Hill\"']\n",
      "Actual Talk Tags: [list(['composing', 'entertainment', 'guitar', 'memory', 'music', 'performance', 'piano'])]\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# create sklearn pipeline for simple fit+transform of talks\n",
    "pipe = Pipeline([\n",
    "    ('tfidf', vectorizer),\n",
    "    ('nmf', nmf)\n",
    "])\n",
    "\n",
    "# test out on 5 randomly sampled talks\n",
    "rand_doc_ids = np.random.randint(0,len(transcript_df),5)\n",
    "for doc_id in rand_doc_ids:\n",
    "    t = pipe.transform([transcript_df['transcript'].iloc[doc_id]]) \n",
    "    print('Predicted most likely topic: ', t_words[np.argmax(t)])\n",
    "    talk_data = main_df[main_df.url == transcript_df.iloc[doc_id]['url']]\n",
    "    print('Talk Title:', talk_data.title.values)\n",
    "    print('Actual Talk Tags:', talk_data.tags.values)\n",
    "    print('----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# applying topic extraction to every talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions to retrieve topic and topic id for each talk in DF\n",
    "def get_topic(transcript):\n",
    "    t = pipe.transform([transcript])\n",
    "    topic = t_words[np.argmax(t)]\n",
    "    return topic\n",
    "\n",
    "def get_topic_id(transcript):\n",
    "    t = pipe.transform([transcript])\n",
    "    return np.argmax(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get topic weights for each transcript\n",
    "weights_df = pd.DataFrame(pipe.transform(transcript_df.transcript))\n",
    "weights_df.columns = ['t1_weight',\n",
    "                      't2_weight',\n",
    "                      't3_weight',\n",
    "                      't4_weight',\n",
    "                      't5_weight',\n",
    "                      't6_weight',\n",
    "                      't7_weight',\n",
    "                      't8_weight',\n",
    "                      't9_weight',\n",
    "                      't10_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map helper functions to entire df\n",
    "transcript_df['topic_pred'] = transcript_df.transcript.map(get_topic)\n",
    "transcript_df['topic_pred_id'] = transcript_df.transcript.map(get_topic_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transcript_df = transcript_df.merge(weights_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>film_date</th>\n",
       "      <th>languages</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>name</th>\n",
       "      <th>num_speaker</th>\n",
       "      <th>published_date</th>\n",
       "      <th>...</th>\n",
       "      <th>t1_weight</th>\n",
       "      <th>t2_weight</th>\n",
       "      <th>t3_weight</th>\n",
       "      <th>t4_weight</th>\n",
       "      <th>t5_weight</th>\n",
       "      <th>t6_weight</th>\n",
       "      <th>t7_weight</th>\n",
       "      <th>t8_weight</th>\n",
       "      <th>t9_weight</th>\n",
       "      <th>t10_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4553</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>60</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063420</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170427</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>977</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>43</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Al Gore: Averting the climate crisis</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027531</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.023396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056169</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>0.120641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>1286</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140739200</td>\n",
       "      <td>26</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>David Pogue: Simplicity sells</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069503</td>\n",
       "      <td>0.059341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>0.133906</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>1116</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140912000</td>\n",
       "      <td>35</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>Majora Carter: Greening the ghetto</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042297</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.017086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087356</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>0.012474</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>593</td>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>1190</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140566400</td>\n",
       "      <td>48</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>Hans Rosling: The best stats you've ever seen</td>\n",
       "      <td>1</td>\n",
       "      <td>1151440680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062717</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments                                        description  duration  \\\n",
       "0      4553  Sir Ken Robinson makes an entertaining and pro...      1164   \n",
       "1       265  With the same humor and humanity he exuded in ...       977   \n",
       "2       124  New York Times columnist David Pogue takes aim...      1286   \n",
       "3       200  In an emotionally charged talk, MacArthur-winn...      1116   \n",
       "4       593  You've never seen data presented like this. Wi...      1190   \n",
       "\n",
       "     event   film_date  languages   main_speaker  \\\n",
       "0  TED2006  1140825600         60   Ken Robinson   \n",
       "1  TED2006  1140825600         43        Al Gore   \n",
       "2  TED2006  1140739200         26    David Pogue   \n",
       "3  TED2006  1140912000         35  Majora Carter   \n",
       "4  TED2006  1140566400         48   Hans Rosling   \n",
       "\n",
       "                                            name  num_speaker published_date  \\\n",
       "0      Ken Robinson: Do schools kill creativity?            1     1151367060   \n",
       "1           Al Gore: Averting the climate crisis            1     1151367060   \n",
       "2                  David Pogue: Simplicity sells            1     1151367060   \n",
       "3             Majora Carter: Greening the ghetto            1     1151367060   \n",
       "4  Hans Rosling: The best stats you've ever seen            1     1151440680   \n",
       "\n",
       "   ... t1_weight t2_weight t3_weight t4_weight t5_weight t6_weight  t7_weight  \\\n",
       "0  ...  0.063420  0.034262  0.002160       0.0  0.000000  0.000000   0.000000   \n",
       "1  ...  0.027531  0.002607  0.023396       0.0  0.056169  0.025449   0.120641   \n",
       "2  ...  0.069503  0.059341  0.000000       0.0  0.009043  0.133906   0.000362   \n",
       "3  ...  0.042297  0.001360  0.017086       0.0  0.089942  0.000000   0.087356   \n",
       "4  ...  0.000000  0.000000  0.000014       0.0  0.166522  0.000000   0.000000   \n",
       "\n",
       "  t8_weight  t9_weight  t10_weight  \n",
       "0  0.000000   0.170427    0.000000  \n",
       "1  0.000000   0.000000    0.000000  \n",
       "2  0.000000   0.000000    0.004225  \n",
       "3  0.007359   0.012474    0.000000  \n",
       "4  0.000000   0.062717    0.000000  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join on data from main_df and display top 5 rows\n",
    "merged_df = main_df.merge(transcript_df, on='url')\n",
    "merged_df.drop('transcript', axis=1, inplace=True)\n",
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get year for each talk\n",
    "merged_df['film_year'] = pd.to_datetime(merged_df.film_date, unit='s').dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top (most-selected) rating for each talk\n",
    "def get_top_rating(rating):\n",
    "    counts = [r['count'] for r in rating]\n",
    "    return rating[np.argmax(counts)]['name']\n",
    "merged_df['top_rating'] = merged_df.ratings.map(get_top_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Beautiful</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Confusing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Courageous</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fascinating</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Funny</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Informative</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ingenious</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Inspiring</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jaw-dropping</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Longwinded</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OK</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Obnoxious</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Persuasive</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Unconvincing</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              url\n",
       "top_rating       \n",
       "Beautiful     142\n",
       "Confusing       2\n",
       "Courageous     82\n",
       "Fascinating   251\n",
       "Funny         159\n",
       "Informative   711\n",
       "Ingenious     101\n",
       "Inspiring     851\n",
       "Jaw-dropping   49\n",
       "Longwinded      8\n",
       "OK              6\n",
       "Obnoxious       3\n",
       "Persuasive     79\n",
       "Unconvincing   23"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show counts of each top rating value\n",
    "merged_df.groupby(['top_rating'])[['url']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_pred_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               url\n",
       "topic_pred_id     \n",
       "0              510\n",
       "1              145\n",
       "2              240\n",
       "3               95\n",
       "4              362\n",
       "5              518\n",
       "6              195\n",
       "7               95\n",
       "8              200\n",
       "9              107"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show counts of each predicted topic\n",
    "merged_df.groupby(['topic_pred_id'])[['url']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>father</td>\n",
       "      <td>god</td>\n",
       "      <td>war</td>\n",
       "      <td>girl</td>\n",
       "      <td>parents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>music</td>\n",
       "      <td>sound</td>\n",
       "      <td>playing</td>\n",
       "      <td>sounds</td>\n",
       "      <td>audience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>species</td>\n",
       "      <td>animals</td>\n",
       "      <td>planet</td>\n",
       "      <td>sea</td>\n",
       "      <td>animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cancer</td>\n",
       "      <td>disease</td>\n",
       "      <td>medical</td>\n",
       "      <td>blood</td>\n",
       "      <td>hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>africa</td>\n",
       "      <td>economic</td>\n",
       "      <td>companies</td>\n",
       "      <td>economy</td>\n",
       "      <td>china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>computer</td>\n",
       "      <td>machine</td>\n",
       "      <td>internet</td>\n",
       "      <td>digital</td>\n",
       "      <td>computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>cities</td>\n",
       "      <td>car</td>\n",
       "      <td>cars</td>\n",
       "      <td>street</td>\n",
       "      <td>driving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>universe</td>\n",
       "      <td>theory</td>\n",
       "      <td>sun</td>\n",
       "      <td>planet</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>students</td>\n",
       "      <td>education</td>\n",
       "      <td>learning</td>\n",
       "      <td>language</td>\n",
       "      <td>schools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>cells</td>\n",
       "      <td>cell</td>\n",
       "      <td>blood</td>\n",
       "      <td>disease</td>\n",
       "      <td>lab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2         3          4\n",
       "0    father        god        war      girl    parents\n",
       "1     music      sound    playing    sounds   audience\n",
       "2   species    animals     planet       sea     animal\n",
       "3    cancer    disease    medical     blood   hospital\n",
       "4    africa   economic  companies   economy      china\n",
       "5  computer    machine   internet   digital  computers\n",
       "6    cities        car       cars    street    driving\n",
       "7  universe     theory        sun    planet      black\n",
       "8  students  education   learning  language    schools\n",
       "9     cells       cell      blood   disease        lab"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each row is a topic, each column is an associated word\n",
    "pd.DataFrame(t_words).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Emulate this with d3 for lollipop chart\\ntopic_dict = {}\\nfor i in range(len(t_words)):\\n    tag_dict = {}\\n    df_filtered = merged_df.loc[merged_df.topic_pred_id == i]\\n    for tag_list in list(df_filtered.tags):\\n        for tag in tag_list:\\n            if tag in tag_dict:\\n                tag_dict[tag] += 1\\n            else:\\n                tag_dict[tag] = 1\\n    top_ten_tags = heapq.nlargest(10, tag_dict.items(), key=operator.itemgetter(1))\\n    topic_dict[i] = top_ten_tags\\ntopic_dict\\n\\n# create demo topic/tag data for lollipop chart prototype, then write out to csv\\ndemo_topic_tag_df = pd.DataFrame(topic_dict[0])\\ndemo_topic_tag_df.columns = ['tag', 'count']\\ndemo_topic_tag_df.to_csv('data/demo_topic_tag.csv')\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IGNORE\n",
    "\"\"\"\n",
    "# Emulate this with d3 for lollipop chart\n",
    "topic_dict = {}\n",
    "for i in range(len(t_words)):\n",
    "    tag_dict = {}\n",
    "    df_filtered = merged_df.loc[merged_df.topic_pred_id == i]\n",
    "    for tag_list in list(df_filtered.tags):\n",
    "        for tag in tag_list:\n",
    "            if tag in tag_dict:\n",
    "                tag_dict[tag] += 1\n",
    "            else:\n",
    "                tag_dict[tag] = 1\n",
    "    top_ten_tags = heapq.nlargest(10, tag_dict.items(), key=operator.itemgetter(1))\n",
    "    topic_dict[i] = top_ten_tags\n",
    "topic_dict\n",
    "\n",
    "# create demo topic/tag data for lollipop chart prototype, then write out to csv\n",
    "demo_topic_tag_df = pd.DataFrame(topic_dict[0])\n",
    "demo_topic_tag_df.columns = ['tag', 'count']\n",
    "demo_topic_tag_df.to_csv('data/demo_topic_tag.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('data/labelled_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
